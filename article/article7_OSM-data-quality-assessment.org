#+TITLE: OSM data quality assessment: producing map to illustrate data quality
#+AUTHOR: Damien Garaud <damien.garaud@oslandia.com>, RaphaÃ«l Delhome <raphael.delhome@oslandia.com>

# Common introduction for articles of the OSM-data-quality series
At [[http://oslandia.com/][Oslandia]], we like working with Open Source tool projects and handling Open
(geospatial) Data. In this article series, we will play with the [[https://www.openstreetmap.org/][OpenStreetMap]]
(/OSM/) map and subsequent data. Here comes the eighth article of this series,
dedicated to the OSM data quality evaluation, through production of new maps.

* Description of OSM element

** Element metadata extraction

As mentionned in a previous article dedicated to [[http://oslandia.com/en/2017/07/24/osm-metadata-description-the-data-behind-the-data/][metadata extraction]], we have
to focus on element metadata itself if we want to produce valuable information
about quality. The first questions to answer here are straightforward: /what is
an OSM element?/ and /how to extract its associated metadata?/. This part is
relatively similar to the job already done with users.

We know from previous analysis that an element is created during a change set
by a given contributor, may be modified several times by whoever, and may be
deleted as well. This kind of object may be either a "node", a "way" or a
"relation". We also know that there may be a set of different tags associated
with the element. Of course the list of every operations associated to each
element is recorded in the OSM data history, so we have to begin with this
structure (let's consider data around Bordeaux, as in previous blog posts):

#+BEGIN_SRC ipython :session osm
import pandas as pd
elements = pd.read_table('../src/data/output-extracts/bordeaux-metropole/bordeaux-metropole-elements.csv', parse_dates=['ts'], index_col=0, sep=",")
elements.head()
#+END_SRC

#+RESULTS:
:    elem        id  version  visible         ts    uid  chgset
: 0  node  21457126        2    False 2008-01-17  24281  653744
: 1  node  21457126        3    False 2008-01-17  24281  653744
: 2  node  21457126        4    False 2008-01-17  24281  653744
: 3  node  21457126        5    False 2008-01-17  24281  653744
: 4  node  21457126        6    False 2008-01-17  24281  653744

This short description helps us to identify some basic features, which are
built in the following snippets. First we recover the temporal features:

#+BEGIN_SRC ipython :session osm
elem_md = (elements.groupby(['elem', 'id'])['ts']
            .agg(["min", "max"])
            .reset_index())
elem_md.columns = ['elem', 'id', 'first_at', 'last_at']
elem_md['lifespan'] = (elem_md.last_at - elem_md.first_at)/pd.Timedelta('1D')
extraction_date = elements.ts.max()
elem_md['n_days_since_creation'] = ((extraction_date - elem_md.first_at)
                                  / pd.Timedelta('1d'))
elem_md['n_days_of_activity'] = (elements
                              .groupby(['elem', 'id'])['ts']
                              .nunique()
                              .reset_index())['ts']
elem_md = elem_md.sort_values(by=['first_at'])
#+END_SRC

#+RESULTS:

Then the remainder of the variables, /e.g./ how many versions, contributors,
changesets per elements:

#+BEGIN_SRC ipython :session osm
    elem_md['version'] = (elements.groupby(['elem','id'])['version']
                          .max()
                          .reset_index())['version']
    elem_md['n_chgset'] = (elements.groupby(['elem', 'id'])['chgset']
                           .nunique()
                           .reset_index())['chgset']
    elem_md['n_user'] = (elements.groupby(['elem', 'id'])['uid']
                         .nunique()
                         .reset_index())['uid']
    osmelem_last_user = (elements
                         .groupby(['elem','id'])['uid']
                         .last()
                         .reset_index())
    osmelem_last_user = osmelem_last_user.rename(columns={'uid':'last_uid'})
    elements = pd.merge(elements, osmelem_last_user,
                       on=['elem', 'id'])
#    elements = elements.join(osmelem_last_user.set_index(['elem', 'id']))
    elem_md = pd.merge(elem_md,
                       elements[['elem', 'id', 'version', 'visible', 'last_uid']],
                       on=['elem', 'id', 'version'])
    elem_md = elem_md.set_index(['elem', 'id'])
    elem_md.sample().T
#+END_SRC

#+RESULTS:
#+begin_example
elem                                  node
id                              1261182084
first_at               2011-04-26 00:00:00
last_at                2011-04-26 00:00:00
lifespan                                 0
n_days_since_creation                 2126
n_days_of_activity                       1
version                                  1
n_chgset                                 1
n_user                                   1
visible                               True
last_uid                            354363
#+end_example

As an illustration we have above an old one-versionned node, still visible on
the OSM website.

** Characterize OSM elements with user classification

This set of features is only descriptive, we have to add more information to be
able to characterize OSM data quality. That is the moment to exploit the user
classification produced in the last blog post!

As a recall, we hypothesized that clustering the users permits to evaluate
their trustworthiness as OSM contributors. They are either beginners, or
intermediate users, or even OSM experts, according to previous classification.

Each OSM entity may have received one or more contributions by users of each
group. Let's say the entity quality is good if its last contributor is
experienced. That leads us to classify the OSM entities themselves in return!

/How to include this information into element metadata?/

We first need to recover the results of our clustering process.

#+BEGIN_SRC ipython :session osm
user_groups = pd.read_hdf("../src/data/output-extracts/bordeaux-metropole/bordeaux-metropole-user-kmeans.h5", "/individuals")
user_groups.head()
#+END_SRC

#+RESULTS:
:            PC1       PC2       PC3       PC4       PC5       PC6  Xclust
: uid                                                                     
: 1626 -0.035154  1.607427  0.399929 -0.808851 -0.152308 -0.753506       2
: 1399 -0.295486 -0.743364  0.149797 -1.252119  0.128276 -0.292328       0
: 2488  0.003268  1.073443  0.738236 -0.534716 -0.489454 -0.333533       2
: 5657 -0.889706  0.986024  0.442302 -1.046582 -0.118883 -0.408223       4
: 3980 -0.115455 -0.373598  0.906908  0.252670  0.207824 -0.575960       5

As a remark, there were several important results to save after the clustering
process; we decided to serialize them into a single binary file. =Pandas= knows
how to manage such file, that would be a pity not to take advantage of it!

We recover the individuals groups in the eponym binary file tab (column
=Xclust=), and only have to join it to element metadata as follows:

#+BEGIN_SRC ipython :session osm
    elem_md = elem_md.join(user_groups.Xclust, on='last_uid')
    elem_md = elem_md.rename(columns={'Xclust':'last_uid_group'})
    elem_md.sample().T
#+END_SRC

#+RESULTS:
#+begin_example
elem                                  node
id                               283046043
first_at               2008-08-03 00:00:00
last_at                2008-08-03 00:00:00
lifespan                                 0
n_days_since_creation                 3122
n_days_of_activity                       1
version                                  1
n_chgset                                 1
n_user                                   1
visible                               True
last_uid                             53048
last_uid_group                           2
#+end_example

From now, we can use the last contributor cluster as an additional information
to generate maps, so as to study data quality...

/Wait... There miss another information, isn't it?/ Well yes, maybe the most
important one, when dealing with geospatial data: the location itself!

** Recover the geometry information

Even if =Pyosmium= library is able to retrieve OSM element geometries, we
realized some test with an other OSM data parser here: =osm2pgsql=.

We can recover geometries from standard OSM data

#+BEGIN_SRC sh
osm2pgsql ../src/data/raw/
#+END_SRC

#+RESULTS:

* Keep it visual, man!

From the last conclusions, we are able to produce some customized maps, based
on hypothesis on entity quality. If each OSM entities (*e.g.* roads) can be
characterized in terms of quality, by the way of a synthetic score for example,
then we can draw quality maps by highlighting the most trustworthy entities, as
well as those with which we have to stay cautious.

** First step: simple metadata plotting

Number of user per roads, number of tags per roads, and so on, within PostGIS

** More complex: OSM data merging with alternative geospatial representations

Use the INSEE carroyed data to provide an alternative way of OSM data
representation: 200-meter squared tiles, within which OSM element statistics
are aggregated

** The cherry on the cake: representation of OSM elements with respect to quality

Design similar map than in previous section, with user classification
information: /e.g./ last contributor group

Idea: identify questionable OSM elements, that should be verified (they are not
necessarily of low quality!)
